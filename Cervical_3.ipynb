{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all necessary libraries to run the code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import NaiveBayesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "# using the variable sw to hold all stopwords that are in English\n",
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "      <th>past</th>\n",
       "      <th>stopwords_removal</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>id</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>fee</th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "      <th>...</th>\n",
       "      <th>stopwords_removal_nltk</th>\n",
       "      <th>present_simple</th>\n",
       "      <th>dataSource</th>\n",
       "      <th>appId</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiScore_pos</th>\n",
       "      <th>present_con</th>\n",
       "      <th>length_words</th>\n",
       "      <th>stopwords_removal_lemmatization</th>\n",
       "      <th>Exclude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Besides the occasional crash, this is an amazi...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>besides occasional crash, this amazing product...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>264</td>\n",
       "      <td>besid the occa crash, thi is an amaz produc wi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Almost perfect</td>\n",
       "      <td>Bug</td>\n",
       "      <td>...</td>\n",
       "      <td>besides occasional crash, amazing product tons...</td>\n",
       "      <td>2</td>\n",
       "      <td>RE2014_app_and_play_store_apps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>besides occasional crash, this amaze product w...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  rating  past  \\\n",
       "0  Besides the occasional crash, this is an amazi...       5     0   \n",
       "\n",
       "                                   stopwords_removal reviewer   id  \\\n",
       "0  besides occasional crash, this amazing product...      NaN  264   \n",
       "\n",
       "                                             stemmed  fee           title  \\\n",
       "0  besid the occa crash, thi is an amaz produc wi...  NaN  Almost perfect   \n",
       "\n",
       "  label   ...                               stopwords_removal_nltk  \\\n",
       "0   Bug   ...    besides occasional crash, amazing product tons...   \n",
       "\n",
       "  present_simple                      dataSource  appId  date sentiScore_pos  \\\n",
       "0              2  RE2014_app_and_play_store_apps    NaN   NaN              3   \n",
       "\n",
       "   present_con length_words  \\\n",
       "0            1           22   \n",
       "\n",
       "                     stopwords_removal_lemmatization Exclude  \n",
       "0  besides occasional crash, this amaze product w...     NaN  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"all.csv\") \n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "      <th>past</th>\n",
       "      <th>stopwords_removal</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>id</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>fee</th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "      <th>...</th>\n",
       "      <th>stopwords_removal_nltk</th>\n",
       "      <th>present_simple</th>\n",
       "      <th>dataSource</th>\n",
       "      <th>appId</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiScore_pos</th>\n",
       "      <th>present_con</th>\n",
       "      <th>length_words</th>\n",
       "      <th>stopwords_removal_lemmatization</th>\n",
       "      <th>Exclude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Besides occasional crash, amazing product tons...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>besides occasional crash, this amazing product...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>264</td>\n",
       "      <td>besid the occa crash, thi is an amaz produc wi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Almost perfect</td>\n",
       "      <td>Bug</td>\n",
       "      <td>...</td>\n",
       "      <td>besides occasional crash, amazing product tons...</td>\n",
       "      <td>2</td>\n",
       "      <td>RE2014_app_and_play_store_apps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>besides occasional crash, this amaze product w...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This could great app predictable, full bugs un...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>this could be great app if was predictable, bu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111</td>\n",
       "      <td>thi could be a gre ap if it was predictable, b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Take a photo of your boarding pass</td>\n",
       "      <td>Bug</td>\n",
       "      <td>...</td>\n",
       "      <td>could great app predictable, full bugs unpredi...</td>\n",
       "      <td>9</td>\n",
       "      <td>AppStore_Random</td>\n",
       "      <td>382698565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>this could be great app if be predictable, but...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  rating  past  \\\n",
       "0  Besides occasional crash, amazing product tons...       5     0   \n",
       "1  This could great app predictable, full bugs un...       1     1   \n",
       "\n",
       "                                   stopwords_removal reviewer   id  \\\n",
       "0  besides occasional crash, this amazing product...      NaN  264   \n",
       "1  this could be great app if was predictable, bu...      NaN  111   \n",
       "\n",
       "                                             stemmed  fee  \\\n",
       "0  besid the occa crash, thi is an amaz produc wi...  NaN   \n",
       "1  thi could be a gre ap if it was predictable, b...  NaN   \n",
       "\n",
       "                                title label   ...    \\\n",
       "0                      Almost perfect   Bug   ...     \n",
       "1  Take a photo of your boarding pass   Bug   ...     \n",
       "\n",
       "                              stopwords_removal_nltk present_simple  \\\n",
       "0  besides occasional crash, amazing product tons...              2   \n",
       "1  could great app predictable, full bugs unpredi...              9   \n",
       "\n",
       "                       dataSource      appId  date sentiScore_pos  \\\n",
       "0  RE2014_app_and_play_store_apps        NaN   NaN              3   \n",
       "1                 AppStore_Random  382698565   NaN              3   \n",
       "\n",
       "   present_con length_words  \\\n",
       "0            1           22   \n",
       "1            0           58   \n",
       "\n",
       "                     stopwords_removal_lemmatization Exclude  \n",
       "0  besides occasional crash, this amaze product w...     NaN  \n",
       "1  this could be great app if be predictable, but...     NaN  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#applying pre-processing steps to remove stopwords and words of size less than 2\n",
    "data['comment'] = data['comment'].apply(lambda x: x.split())\n",
    "wordsEng = stopwords.words('english')\n",
    "data['comment'] = data['comment'].apply(lambda x:[item for item in x if item not in wordsEng])\n",
    "data['comment'] = data['comment'].apply(lambda x: [w for w in x if len(w)>2])\n",
    "data['comment'] = data['comment'].apply(lambda x: \" \".join(x))\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the variable sw to hold all stopwords that are in English\n",
    "sw = stopwords.words('english')\n",
    "TEXT=[]\n",
    "#Rating=[]\n",
    "for i in range(len(data)):\n",
    "    #if data['cetagory'][i]=='Racing':\n",
    "    review = re.sub('[^a-zA-Z]', ' ',data['comment'][i])\n",
    "    #review = re.sub('[/(){}\\[\\]\\|@!,;]', ' ',data['reviews'][i])\n",
    "    #review = re.sub('[^0-9a-zA-Z #+_♥️]', ' ',data['reviews'][i])#Remove bad symbols\n",
    "    review = re.sub(r'\\d+', '',review)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "\n",
    "    review = [token for token in review if token not in sw]\n",
    "    review=' '.join(review)\n",
    "    TEXT.append(review)\n",
    "    #Rating.append(data['rating'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all necessary libraries to run the code\n",
    "import re,string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras_metrics\n",
    "import tensorflow.keras\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation,Embedding,GlobalMaxPooling1D\n",
    "# using the variable sw to hold all stopwords that are in English\n",
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>besides occasional crash amazing product tons ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>could great app predictable full bugs unpredic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  besides occasional crash amazing product tons ...\n",
       "1  could great app predictable full bugs unpredic..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting twitterSentiment[] list into dataframe for serving it to keras tokenizer\n",
    "dataSetFinal = pd.DataFrame(np.array(TEXT))\n",
    "dataSetFinal.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tensorflow.keras.preprocessing.text.Tokenizer(num_words=2500, lower=True,split=' ',filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(dataSetFinal[0].values)\n",
    "#print(tokenizer.word_index)  # To see the dicstionary\n",
    "X = tokenizer.texts_to_sequences(dataSetFinal[0].values)\n",
    "X = tensorflow.keras.preprocessing.sequence.pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 23, 100)           250000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 23, 64)            32064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 11, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 11, 64)            20544     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 304,754\n",
      "Trainable params: 304,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "weight_decay = 1e-4\n",
    "#Deep Learning Network Structure\n",
    "model = Sequential()\n",
    "model.add(Embedding(2500,100, input_length=X.shape[1]))\n",
    "model.add(Conv1D(64, 5, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(64, 5, activation='relu', padding='same'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy','mae','mse',keras_metrics.precision(), keras_metrics.recall()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2583 samples, validate on 1108 samples\n",
      "Epoch 1/50\n",
      " - 135s - loss: 1.2644 - acc: 0.5947 - mean_absolute_error: 0.2538 - mean_squared_error: 0.1253 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.1311 - val_acc: 0.5975 - val_mean_absolute_error: 0.2231 - val_mean_squared_error: 0.1126 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      " - 109s - loss: 1.0551 - acc: 0.6148 - mean_absolute_error: 0.2122 - mean_squared_error: 0.1047 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.9953 - val_acc: 0.5975 - val_mean_absolute_error: 0.2080 - val_mean_squared_error: 0.1001 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/50\n",
      " - 67s - loss: 0.9010 - acc: 0.6353 - mean_absolute_error: 0.1838 - mean_squared_error: 0.0910 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.9695 - val_acc: 0.6444 - val_mean_absolute_error: 0.1966 - val_mean_squared_error: 0.0980 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/50\n",
      " - 84s - loss: 0.8209 - acc: 0.6880 - mean_absolute_error: 0.1701 - mean_squared_error: 0.0841 - precision: 0.6667 - recall: 0.1191 - val_loss: 0.9898 - val_acc: 0.6417 - val_mean_absolute_error: 0.1816 - val_mean_squared_error: 0.0975 - val_precision: 0.4667 - val_recall: 0.1308\n",
      "Epoch 5/50\n",
      " - 86s - loss: 0.7552 - acc: 0.6961 - mean_absolute_error: 0.1595 - mean_squared_error: 0.0790 - precision: 0.6165 - recall: 0.3489 - val_loss: 1.0716 - val_acc: 0.6399 - val_mean_absolute_error: 0.1718 - val_mean_squared_error: 0.0986 - val_precision: 0.5000 - val_recall: 0.2804\n",
      "Epoch 6/50\n",
      " - 65s - loss: 0.7071 - acc: 0.7031 - mean_absolute_error: 0.1502 - mean_squared_error: 0.0751 - precision: 0.6828 - recall: 0.5404 - val_loss: 1.0603 - val_acc: 0.6552 - val_mean_absolute_error: 0.1830 - val_mean_squared_error: 0.0984 - val_precision: 0.5517 - val_recall: 0.2991\n",
      "Epoch 7/50\n",
      " - 106s - loss: 0.6683 - acc: 0.7189 - mean_absolute_error: 0.1450 - mean_squared_error: 0.0713 - precision: 0.7264 - recall: 0.6213 - val_loss: 1.1375 - val_acc: 0.6408 - val_mean_absolute_error: 0.1802 - val_mean_squared_error: 0.1011 - val_precision: 0.4737 - val_recall: 0.4206\n",
      "Epoch 8/50\n",
      " - 111s - loss: 0.6364 - acc: 0.7333 - mean_absolute_error: 0.1397 - mean_squared_error: 0.0686 - precision: 0.7143 - recall: 0.7021 - val_loss: 1.2234 - val_acc: 0.6245 - val_mean_absolute_error: 0.1833 - val_mean_squared_error: 0.1043 - val_precision: 0.4545 - val_recall: 0.4673\n",
      "Epoch 9/50\n",
      " - 99s - loss: 0.6059 - acc: 0.7627 - mean_absolute_error: 0.1333 - mean_squared_error: 0.0653 - precision: 0.7185 - recall: 0.7277 - val_loss: 1.2930 - val_acc: 0.6164 - val_mean_absolute_error: 0.1832 - val_mean_squared_error: 0.1058 - val_precision: 0.5395 - val_recall: 0.3832\n",
      "Epoch 10/50\n",
      " - 67s - loss: 0.5501 - acc: 0.7921 - mean_absolute_error: 0.1211 - mean_squared_error: 0.0590 - precision: 0.7664 - recall: 0.7957 - val_loss: 1.3805 - val_acc: 0.6038 - val_mean_absolute_error: 0.1815 - val_mean_squared_error: 0.1111 - val_precision: 0.4757 - val_recall: 0.4579\n",
      "Epoch 11/50\n",
      " - 65s - loss: 0.5124 - acc: 0.8084 - mean_absolute_error: 0.1134 - mean_squared_error: 0.0546 - precision: 0.7344 - recall: 0.7532 - val_loss: 1.4886 - val_acc: 0.6218 - val_mean_absolute_error: 0.1775 - val_mean_squared_error: 0.1125 - val_precision: 0.4951 - val_recall: 0.4766\n",
      "Epoch 12/50\n",
      " - 65s - loss: 0.4812 - acc: 0.8215 - mean_absolute_error: 0.1054 - mean_squared_error: 0.0509 - precision: 0.7540 - recall: 0.8085 - val_loss: 1.6119 - val_acc: 0.6236 - val_mean_absolute_error: 0.1701 - val_mean_squared_error: 0.1151 - val_precision: 0.5182 - val_recall: 0.5327\n",
      "Epoch 13/50\n",
      " - 65s - loss: 0.4561 - acc: 0.8308 - mean_absolute_error: 0.0998 - mean_squared_error: 0.0486 - precision: 0.7676 - recall: 0.7872 - val_loss: 1.6207 - val_acc: 0.6200 - val_mean_absolute_error: 0.1702 - val_mean_squared_error: 0.1160 - val_precision: 0.5250 - val_recall: 0.3925\n",
      "Epoch 14/50\n",
      " - 65s - loss: 0.4280 - acc: 0.8343 - mean_absolute_error: 0.0936 - mean_squared_error: 0.0458 - precision: 0.7932 - recall: 0.8000 - val_loss: 1.8096 - val_acc: 0.5903 - val_mean_absolute_error: 0.1818 - val_mean_squared_error: 0.1227 - val_precision: 0.5000 - val_recall: 0.4486\n",
      "Epoch 15/50\n",
      " - 66s - loss: 0.4064 - acc: 0.8506 - mean_absolute_error: 0.0900 - mean_squared_error: 0.0429 - precision: 0.8405 - recall: 0.8298 - val_loss: 1.7701 - val_acc: 0.5884 - val_mean_absolute_error: 0.1824 - val_mean_squared_error: 0.1217 - val_precision: 0.4808 - val_recall: 0.4673\n",
      "Epoch 16/50\n",
      " - 65s - loss: 0.3985 - acc: 0.8494 - mean_absolute_error: 0.0858 - mean_squared_error: 0.0422 - precision: 0.8159 - recall: 0.8298 - val_loss: 1.9147 - val_acc: 0.6056 - val_mean_absolute_error: 0.1746 - val_mean_squared_error: 0.1244 - val_precision: 0.5000 - val_recall: 0.3925\n",
      "Epoch 17/50\n",
      " - 66s - loss: 0.3758 - acc: 0.8637 - mean_absolute_error: 0.0812 - mean_squared_error: 0.0399 - precision: 0.8462 - recall: 0.8426 - val_loss: 1.8934 - val_acc: 0.6092 - val_mean_absolute_error: 0.1752 - val_mean_squared_error: 0.1222 - val_precision: 0.5357 - val_recall: 0.4206\n",
      "Epoch 18/50\n",
      " - 65s - loss: 0.3392 - acc: 0.8765 - mean_absolute_error: 0.0761 - mean_squared_error: 0.0365 - precision: 0.8528 - recall: 0.8383 - val_loss: 1.9940 - val_acc: 0.6110 - val_mean_absolute_error: 0.1692 - val_mean_squared_error: 0.1218 - val_precision: 0.5753 - val_recall: 0.3925\n",
      "Epoch 19/50\n",
      " - 67s - loss: 0.3495 - acc: 0.8746 - mean_absolute_error: 0.0749 - mean_squared_error: 0.0370 - precision: 0.8800 - recall: 0.8426 - val_loss: 2.0113 - val_acc: 0.6065 - val_mean_absolute_error: 0.1704 - val_mean_squared_error: 0.1239 - val_precision: 0.6383 - val_recall: 0.2804\n",
      "Epoch 20/50\n",
      " - 65s - loss: 0.3442 - acc: 0.8819 - mean_absolute_error: 0.0744 - mean_squared_error: 0.0362 - precision: 0.8884 - recall: 0.8809 - val_loss: 2.1259 - val_acc: 0.6182 - val_mean_absolute_error: 0.1643 - val_mean_squared_error: 0.1235 - val_precision: 0.5970 - val_recall: 0.3738\n",
      "Epoch 21/50\n",
      " - 67s - loss: 0.3250 - acc: 0.8850 - mean_absolute_error: 0.0714 - mean_squared_error: 0.0345 - precision: 0.9123 - recall: 0.8851 - val_loss: 2.2686 - val_acc: 0.5966 - val_mean_absolute_error: 0.1741 - val_mean_squared_error: 0.1296 - val_precision: 0.5663 - val_recall: 0.4393\n",
      "Epoch 22/50\n",
      " - 66s - loss: 0.2958 - acc: 0.8997 - mean_absolute_error: 0.0653 - mean_squared_error: 0.0316 - precision: 0.9123 - recall: 0.8851 - val_loss: 2.3054 - val_acc: 0.6101 - val_mean_absolute_error: 0.1747 - val_mean_squared_error: 0.1276 - val_precision: 0.6053 - val_recall: 0.4299\n",
      "Epoch 23/50\n",
      " - 65s - loss: 0.2950 - acc: 0.9005 - mean_absolute_error: 0.0644 - mean_squared_error: 0.0317 - precision: 0.8945 - recall: 0.9021 - val_loss: 2.3800 - val_acc: 0.6155 - val_mean_absolute_error: 0.1687 - val_mean_squared_error: 0.1284 - val_precision: 0.6190 - val_recall: 0.3645\n",
      "Epoch 24/50\n",
      " - 64s - loss: 0.2938 - acc: 0.8993 - mean_absolute_error: 0.0633 - mean_squared_error: 0.0307 - precision: 0.9174 - recall: 0.8979 - val_loss: 2.4999 - val_acc: 0.5921 - val_mean_absolute_error: 0.1775 - val_mean_squared_error: 0.1356 - val_precision: 0.5694 - val_recall: 0.3832\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-7a78b030ddec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Here we train the Network.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_conv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#LSTM\n",
    "batch_size=64\n",
    "Y = pd.get_dummies(data['rating']).values\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X,Y, test_size = 0.30)\n",
    "#Here we train the Network.\n",
    "pred=model.fit(X_train, Y_train, batch_size =batch_size, epochs =50, verbose =2,validation_data=(X_valid,Y_valid))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.39\n",
      "validation accuracy: 0.92\n",
      "Precision: 0.93\n",
      "Recacll: 0.96\n",
      "Mean Absolute Error: 0.08\n",
      "Mean Squared Error: 0.07\n"
     ]
    }
   ],
   "source": [
    "#LSTM\n",
    "score=[]\n",
    "score=model.evaluate(X_valid,Y_valid,verbose=2,batch_size=batch_size)\n",
    "#keras.metrics.binary_accuracy(Y_valid,pred)\n",
    "print(\"score: %.2f\" %(score[0]))\n",
    "print(\"validation accuracy: %.2f\" % (score[1]))\n",
    "print(\"Precision: %.2f\" %(score[4]))\n",
    "print(\"Recacll: %.2f\" %(score[5]))\n",
    "print(\"Mean Absolute Error: %.2f\" % (score[2]))\n",
    "print(\"Mean Squared Error: %.2f\" % (score[3]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
